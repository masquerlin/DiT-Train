# DiT扩散模型实现说明文档

本项目实现了一个基于Diffusion Transformer (DiT) 的图像生成模型，将Transformer架构与扩散模型相结合，用于高质量图像生成任务。

## 模型架构

### 架构概览

![DiT模型架构](./assets/dit_graph.png)

上图展示了完整的DiT模型架构，主要包含：
- 输入层：包括图像patch嵌入、时间嵌入和标签嵌入
- 主干网络：3个DiT块，每个块包含自注意力层和前馈网络
- 条件控制：使用时间和标签信息调制每个DiT块
- 输出层：生成预测的噪声或图像

## 训练过程

### 训练效果

![训练损失曲线](./assets/training_loss.png)

训练损失曲线展示了模型的学习过程：
- 横轴：训练轮次（Epoch）
- 纵轴：L1损失值
- 蓝线：每个batch的训练损失
- 橙线：每个epoch的平均损失

从损失曲线可以观察到：
- 模型训练过程的稳定性
- 损失值的总体下降趋势
- 收敛情况
### 核心组件

1. **DiT模型结构**
   - 图像尺寸：256×256像素
   - 图像块大小：4×4
   - 通道数：3（RGB）
   - DiT块数量：3
   - 注意力头数：6
   - 嵌入维度：64
   - 标签数量：1

2. **时间嵌入模块**
   - 频率嵌入维度：256
   - 采用正弦位置编码
   - 包含MLP变换层

3. **DiT块结构**
   - 多头自注意力机制
   - 前馈神经网络
   - 层归一化
   - 自适应层参数（α, β, γ）

## 训练过程

### 数据集
- 自定义熊猫数据集
- 图像预处理并归一化到[-1, 1]范围
- 使用持久化工作进程加载数据（num_workers=10）

### 训练配置
- 优化器：Adam
- 学习率：1e-6
- 损失函数：L1损失
- 批量大小：通过`config.py`配置
- 扩散步数：在`config.py`中通过`max_t`定义
- 运行设备：支持GPU（CUDA）

### 扩散过程
- β值调度：从0.0001线性增加到0.02
- 前向过程：逐步添加高斯噪声
- 反向过程：迭代去噪
- 使用预计算值进行方差调度

### 监控与可视化
- 集成TensorBoard进行训练监控
- 追踪指标包括：
  - 每批次损失
  - 每轮平均损失
  - 噪声预测直方图
  - 生成样本图像
- 通过TensorBoard可视化模型架构

### 模型保存
- 定期保存模型状态
- 支持从保存点继续训练
- 检查点路径可配置

## 训练特性

1. **渐进式训练**
   - 支持增量训练
   - 自动加载已有检查点

2. **可视化功能**
   - 定期生成样本图像
   - 可视化训练进度
   - 批次级和轮次级指标追踪

3. **性能优化**
   - 持久化工作进程提升数据加载效率
   - GPU加速支持
   - 可配置的批量大小和工作进程数

## 使用方法

1. **环境配置**
   ```bash
   # 所需包
   torch
   torchvision
   tensorboard
   tqdm
   ```

2. **开始训练**
   ```python
   python train.py
   ```

3. **监控训练**
   ```bash
   tensorboard --logdir=./dit_training
   ```

## 模型输出

模型通过迭代去噪过程生成图像：
- 从随机噪声开始
- 通过多步迭代逐步细化图像
- 最终输出限制在[-1, 1]范围内
- 支持基于标签的条件生成

## 实现细节

- 使用自定义的图像块嵌入层处理图像块
- 位置嵌入为可学习参数
- 扩散过程采用预计算调度提高效率
- 训练过程包含梯度裁剪以保持稳定性
- 定期可视化以监控训练进度

## 自定义配置

模型架构和训练过程可通过以下方式自定义：
- `config.py`：通用设置
- `train.py`中的模型初始化参数
- `dataset.py`中的数据集配置

## 注意事项

1. **硬件要求**
   - 建议使用GPU进行训练
   - 需要足够的显存支持所选批量大小

2. **训练建议**
   - 建议先在小数据集上测试
   - 定期检查生成的样本质量
   - 根据实际情况调整学习率和批量大小

3. **故障排除**
   - 如遇内存不足，可减小批量大小
   - 如遇训练不稳定，可调整学习率或增加梯度裁剪
   - 确保数据预处理正确，图像已正确归一化